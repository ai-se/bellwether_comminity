{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import SMOTE\n",
    "import feature_selector\n",
    "\n",
    "from metrics import abcd\n",
    "import metrices\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('/Users/suvodeepmajumder/Documents/AI4SE/git_miner/data/hadoop_commit.pkl')\n",
    "df1 = df[df['buggy'] == 1]\n",
    "X1 = df1.commit_number\n",
    "X2 = df1.parent\n",
    "X = np.append(X1,X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/suvodeepmajumder/Documents/AI4SE/bellwether_comminity/data/commit_guru/hadoop.csv')\n",
    "df = df[df['commit_hash'].isin(X)]\n",
    "df = df.drop(labels = ['commit_hash', 'author_name', 'author_date_unix_timestamp',\n",
    "       'author_email', 'author_date', 'commit_message','classification', 'linked', 'contains_bug', 'fixes',\n",
    "                      'fileschanged','glm_probability', 'rf_probability',\n",
    "       'repository_id', 'issue_id', 'issue_date', 'issue_type'],axis=1)\n",
    "df = df.dropna()\n",
    "df = df[['ns', 'nd', 'nf', 'entropy', 'la', 'ld', 'lt', 'ndev', 'age',\n",
    "       'nuc', 'exp', 'rexp', 'sexp','fix']]\n",
    "df = df.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ns</th>\n",
       "      <th>nd</th>\n",
       "      <th>nf</th>\n",
       "      <th>entropy</th>\n",
       "      <th>la</th>\n",
       "      <th>ld</th>\n",
       "      <th>lt</th>\n",
       "      <th>ndev</th>\n",
       "      <th>age</th>\n",
       "      <th>nuc</th>\n",
       "      <th>exp</th>\n",
       "      <th>rexp</th>\n",
       "      <th>sexp</th>\n",
       "      <th>fix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ns, nd, nf, entropy, la, ld, lt, ndev, age, nuc, exp, rexp, sexp, fix]\n",
       "Index: []"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('ant_updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[-1] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-381ecde73b65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatureSelector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_selected\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfs_bfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/AI4SE/bellwether_comminity/src/feature_selector.py\u001b[0m in \u001b[0;36mcfs_bfs\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    311\u001b[0m                     \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                     \u001b[0;31m# calculate the merit of current selected features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m                     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerit_S\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/AI4SE/bellwether_comminity/src/feature_selector.py\u001b[0m in \u001b[0;36mmerit_S\u001b[0;34m(fs, cf, ff)\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \"\"\"\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0mr_cf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m             \u001b[0mr_ff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2932\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2933\u001b[0m             indexer = self.loc._convert_to_indexer(key, axis=1,\n\u001b[0;32m-> 2934\u001b[0;31m                                                    raise_missing=True)\n\u001b[0m\u001b[1;32m   2935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1352\u001b[0m                 kwargs = {'raise_missing': True if is_setter else\n\u001b[1;32m   1353\u001b[0m                           raise_missing}\n\u001b[0;32m-> 1354\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         self._validate_read_indexer(keyarr, indexer,\n\u001b[1;32m   1160\u001b[0m                                     \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                                     raise_missing=raise_missing)\n\u001b[0m\u001b[1;32m   1162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1250\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'loc'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} not in index\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m             \u001b[0;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '[-1] not in index'"
     ]
    }
   ],
   "source": [
    "fs = feature_selector.featureSelector()\n",
    "df,_selected,selected = fs.cfs_bfs(df)\n",
    "cols = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.33 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-7fa734f4321e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fix'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2098\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m     n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size,\n\u001b[0;32m-> 2100\u001b[0;31m                                               default_test_size=0.25)\n\u001b[0m\u001b[1;32m   2101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   1780\u001b[0m             \u001b[0;34m'resulting train set will be empty. Adjust any of the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m             'aforementioned parameters.'.format(n_samples, test_size,\n\u001b[0;32m-> 1782\u001b[0;31m                                                 train_size)\n\u001b[0m\u001b[1;32m   1783\u001b[0m         )\n\u001b[1;32m   1784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.33 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "y = df.fix\n",
    "y=y.astype('bool')\n",
    "X = df.drop(labels=['fix'],axis=1)\n",
    "train_X,test_X,train_y,test_y = train_test_split(X, y, test_size=0.33, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3992, 7)\n",
      "(4778, 7)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "df_new = train_X\n",
    "df_new['fix'] = train_y\n",
    "smt = SMOTE.smote(train_X)\n",
    "df = smt.run()\n",
    "df.columns = cols\n",
    "train_y = df.fix\n",
    "train_y=train_y.astype('bool')\n",
    "train_X = df.drop(labels=['fix'],axis=1)\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(penalty= 'l2', multi_class= 'ovr',\n",
    "                         C= 48.488, dual= True, fit_intercept= False, intercept_scaling =  54.623,\n",
    "                         class_weight= None, solver= 'liblinear',\n",
    "                         warm_start= False, max_iter= 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = LogisticRegression(penalty='l1')\n",
    "#clf = RandomForestClassifier(criterion = 'gini',n_estimators=100)\n",
    "clf = SVC(kernel='linear', probability=True)\n",
    "#clf = linear_model.SGDClassifier(loss = 'modified_huber',max_iter=1000, tol=1e-3,penalty='l1')\n",
    "#clf = KNeighborsClassifier(n_neighbors=5,algorithm='kd_tree')\n",
    "#kernel = 1.0 * RBF(1.0)\n",
    "#clf = GaussianProcessClassifier(kernel=kernel,random_state=0)\n",
    "clf.fit(train_X,train_y)\n",
    "predicted = clf.predict(test_X)\n",
    "#fpr, tpr, thresholds = metrics.roc_curve(test_y, predicted[:, 1], pos_label=1)\n",
    "#print(metrics.auc(fpr, tpr))\n",
    "print(classification_report(test_y, predicted))\n",
    "#print(clf.coef_)\n",
    "#plt.plot(fpr, tpr, lw=1, alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(test_y, predicted, labels=[0, 1]).ravel()\n",
    "pd = int(100 * tp / (tp + fn + 1e-5))\n",
    "pf = int(100 * fp / (fp + tn + 1e-5))\n",
    "print(pd,pf)\n",
    "beta = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas = metrices.measures(test_y,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4167741935483871"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meas.get_g_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For using with r package\n",
    "train_df = train_X\n",
    "test_df = test_X\n",
    "train_df['fix'] = train_y.values\n",
    "test_df['fix'] = test_y.values\n",
    "\n",
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "    train_df_r = ro.conversion.py2rpy(train_df)\n",
    "    test_df_r = ro.conversion.py2rpy(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = importr('stats', robject_translations={'format_perc': '_format_perc'})\n",
    "base = importr('base')\n",
    "sig_threshold = 0.05\n",
    "def _isMetricSignificant(formula_metrics, metric,data):\n",
    "    \"\"\"\n",
    "    Checks if adding a metric to the already significant metrics in formula_metrics in a GLM model is significant. If significant,\n",
    "    and doesn't cause any previous metric in formula_metrics to become non significant, we return true. Otherwise, false.\n",
    "    Note: The p-value is always given in the 4th column of the summary matrix!\n",
    "    \"\"\"\n",
    "    sig_column = 4\n",
    "\n",
    "    # Case 1: no existing metrics in the formula\n",
    "    if len(formula_metrics) == 0:\n",
    "        formula = \"fix~\" + metric\n",
    "        fit = stats.glm(formula, data=data, family=\"binomial\")\n",
    "        summary = base.summary(fit)\n",
    "      # Note - first row is the intercept information so we start at second row!\n",
    "\n",
    "        try:\n",
    "            metric_sig = summary.rx2('coefficients').rx(2,sig_column)[0] # Second row, 4th column of the summary matrix.\n",
    "            if metric_sig <= sig_threshold:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "        except:\n",
    "            # If we have two metrics that are perfectly collinear it will not build the model with the metrics\n",
    "            # and we will get an exception when trying to find the significance of *all values*. Indeed, do not add\n",
    "            # this value to the model!\n",
    "            return False\n",
    "\n",
    "    # Case 2: existing metrics in the formula    \n",
    "    else:\n",
    "        num_metrics = len(formula_metrics)+2 # plus one for the new metric we are adding and one for intercept\n",
    "        formula = \"fix~\" + \"+\".join(formula_metrics) + \"+\" + metric\n",
    "        fit = stats.glm(formula, data=data, family=\"binomial\")\n",
    "        summary = base.summary(fit)\n",
    "\n",
    "      # If any metric is now not significant, than we should not have added this metric to the formula\n",
    "      # There are (intercept) + num_metrics rows in the matrix to check - starts at second row skipping intercept\n",
    "        try: \n",
    "            for row in range(2,num_metrics+1):\n",
    "                metric_sig = summary.rx2('coefficients').rx(row,sig_column)[0]\n",
    "                if metric_sig > sig_threshold:\n",
    "                    return False\n",
    "            return True # old metrics added to model ARE significant still as well as the new one being tested\n",
    "\n",
    "        except:\n",
    "            # If we have two metrics that are perfectly collinear it will not build the model with the metrics\n",
    "            # and we will get an exception when trying to find the significance of *all values*. Indeed, do not add\n",
    "            # this value to the model!\n",
    "            return False\n",
    "\n",
    "        \n",
    "def _getInterceptValue(coefs, data):\n",
    "    \"\"\"\n",
    "    Return the Intercept value of a GLM model and the p-value\n",
    "    Assumes that model can be built!\n",
    "    \"\"\"\n",
    "    formula = \"fix~\" + \"+\".join(coefs)\n",
    "    print(formula)\n",
    "    fit = stats.glm(formula, data=data, family=\"binomial\")\n",
    "    summary = base.summary(fit)\n",
    "    return summary.rx2('coefficients').rx(1)[0], summary.rx2('coefficients').rx(1,4)[0]\n",
    "\n",
    "def _getCoefficients(formula_coefs,data):\n",
    "    \"\"\"\n",
    "    Builds a GLM model with a formula based on the passed in coefficients and retuns a dictionary containing each\n",
    "    coefficient with its value.\n",
    "    \"\"\"\n",
    "    coef_dict = {} # a dict containing glm coefficients {name -> value}\n",
    "    formula = \"fix~\" + \"+\".join(formula_coefs)\n",
    "    fit = stats.glm(formula, data=data, family=\"binomial\")\n",
    "\n",
    "    for coef in formula_coefs:\n",
    "        coef_dict[coef] = fit.rx2('coefficients').rx2(coef)[0]\n",
    "\n",
    "    return coef_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = [\"la\",\"ld\",\"lt\",\"ns\",\"nd\",\"nf\",\"ndev\",\"age\",\"nuc\",\"exp\",\"rexp\",\"sexp\",\"entropy\"]\n",
    "formula_metrics = []\n",
    "for metric in metrics_list:\n",
    "    if _isMetricSignificant(formula_metrics, metric,train_df_r):\n",
    "        formula_metrics.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept_value, intercept_pvalue = _getInterceptValue(formula_metrics,train_df_r)\n",
    "coefs = _getCoefficients(formula_metrics,train_df_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = []\n",
    "risks = []\n",
    "predicted_t = []\n",
    "predicted_f = []\n",
    "for commit in test_X.itertuples():\n",
    "    coefs_sum = 0\n",
    "    for coef_name in coefs:\n",
    "        coefs_sum += (coefs[coef_name] * getattr(commit, coef_name))\n",
    "    try:\n",
    "        riskyness = 1/(1+ math.exp(-intercept_value-coefs_sum))\n",
    "    except:\n",
    "        riskyness = -1\n",
    "    if riskyness >= 0.5:\n",
    "        result = True\n",
    "    else:\n",
    "        result = False\n",
    "    predicted.append(result)\n",
    "    risks.append(riskyness)\n",
    "y_train = test_y.values\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i]:\n",
    "        predicted_t.append(risks[i])\n",
    "    else:\n",
    "        predicted_f.append(risks[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_y, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(predicted_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(predicted_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# #############################################################################\n",
    "# Data IO and generation\n",
    "\n",
    "# Import some data to play with\n",
    "y = df.fix\n",
    "y=y.astype('bool')\n",
    "X = df.drop(labels=['fix'],axis=1)\n",
    "X.reset_index(drop=True,inplace=True)\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Classification and ROC analysis\n",
    "\n",
    "# Run classifier with cross-validation and plot ROC curves\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "classifier = LogisticRegression(penalty='l1',class_weight = 'balanced')\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "i = 0\n",
    "for train, test in cv.split(X, y):\n",
    "    probas_ = classifier.fit(X[train], y[train]).predict_proba(X[test])\n",
    "    # Compute ROC curve and area the curve\n",
    "    fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=1, alpha=0.3,\n",
    "             label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "    i += 1\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
