{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import platform\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import SMOTE\n",
    "import feature_selector\n",
    "import DE\n",
    "import CFS\n",
    "\n",
    "import metrices\n",
    "import measures\n",
    "\n",
    "import sys\n",
    "import traceback\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source1 = '/Users/suvodeepmajumder/Documents/AI4SE/bellwether_comminity/data/commit_guru'\n",
    "if platform.system() == 'Darwin' or platform.system() == 'Linux':\n",
    "    _dir = data_source1 + '/'\n",
    "else:\n",
    "    _dir = data_source1 + '\\\\'\n",
    "projects1 = [f for f in listdir(_dir) if isfile(join(_dir, f))]\n",
    "\n",
    "data_source2 = '/Users/suvodeepmajumder/Documents/AI4SE/git_miner/data'\n",
    "if platform.system() == 'Darwin' or platform.system() == 'Linux':\n",
    "    _dir = data_source2 + '/'\n",
    "else:\n",
    "    _dir = data_source2 + '\\\\'\n",
    "projects2 = [f for f in listdir(_dir) if isfile(join(_dir, f))]\n",
    "\n",
    "commit_list = []\n",
    "for project in projects2:\n",
    "    x = project.split('_commit')[0]\n",
    "    if x not in commit_list:\n",
    "        commit_list.append(x)\n",
    "commit_list = set(commit_list)\n",
    "\n",
    "guru_list = []\n",
    "for project in projects1:\n",
    "    x = project.split('.csv')[0]\n",
    "    if x not in guru_list:\n",
    "        guru_list.append(x)\n",
    "guru_list = set(guru_list)\n",
    "\n",
    "if (commit_list & guru_list): \n",
    "    common_list = commit_list & guru_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(path,X):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df[df['commit_hash'].isin(X)]\n",
    "    df = df.drop(labels = ['commit_hash', 'author_name', 'author_date_unix_timestamp',\n",
    "       'author_email', 'author_date', 'commit_message','classification', 'linked', 'contains_bug', 'fixes',\n",
    "                      'fileschanged','glm_probability', 'rf_probability',\n",
    "       'repository_id', 'issue_id', 'issue_date', 'issue_type'],axis=1)\n",
    "    df = df.dropna()\n",
    "    df = df[['ns', 'nd', 'nf', 'entropy', 'la', 'ld', 'lt', 'ndev', 'age',\n",
    "           'nuc', 'exp', 'rexp', 'sexp','fix']]\n",
    "    df = df.astype(np.float64)\n",
    "    return df\n",
    "\n",
    "def get_features(df):\n",
    "    fs = feature_selector.featureSelector()\n",
    "    df,_feature_nums,features = fs.cfs_bfs(df)\n",
    "    return df,features\n",
    "\n",
    "def apply_cfs(df):\n",
    "    y = df.fix.values\n",
    "    X = df.drop(labels = ['fix'],axis = 1)\n",
    "    X = X.values\n",
    "    selected_cols = CFS.cfs(X,y)\n",
    "    cols = df.columns[[selected_cols]].tolist()\n",
    "    cols.append('fix')\n",
    "    return df[cols],cols\n",
    "    \n",
    "def apply_smote(df):\n",
    "    cols = df.columns\n",
    "    smt = SMOTE.smote(df)\n",
    "    df = smt.run()\n",
    "    df.columns = cols\n",
    "    return df\n",
    "\n",
    "def tune_learner(learner, train_X, train_Y, tune_X, tune_Y, goal,target_class=None):\n",
    "    if not target_class:\n",
    "        target_class = goal\n",
    "    clf = learner(train_X, train_Y, tune_X, tune_Y, goal)\n",
    "    tuner = DE.DE_Tune_ML(clf, clf.get_param(), goal, target_class)\n",
    "    return tuner.Tune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DE_Learners(object):\n",
    "    def __init__(self, clf, train_X, train_Y, test_X, test_Y, goal):\n",
    "        \"\"\"\n",
    "\n",
    "        :param clf: classifier, SVM, etc...\n",
    "        :param train_X: training data, independent variables.\n",
    "        :param train_Y: training labels, dependent variables.\n",
    "        :param predict_X: testing data, independent variables.\n",
    "        :param predict_Y: testingd labels, dependent variables.\n",
    "        :param goal: the objective of your tuning, F, recision,....\n",
    "        \"\"\"\n",
    "        self.train_X = train_X\n",
    "        self.train_Y = train_Y\n",
    "        self.test_X = test_X\n",
    "        self.test_Y = test_Y\n",
    "        self.goal = goal\n",
    "        self.param_distribution = self.get_param()\n",
    "        self.learner = clf\n",
    "        self.confusion = None\n",
    "        self.params = None\n",
    "\n",
    "    def learn(self,F, **kwargs):\n",
    "        \"\"\"\n",
    "        :param F: a dict, holds all scores, can be used during debugging\n",
    "        :param kwargs: a dict, all the parameters need to set after tuning.\n",
    "        :return: F, scores.\n",
    "        \"\"\"\n",
    "        self.scores = {self.goal: [0.0]}\n",
    "        try:    \n",
    "            self.learner.set_params(**kwargs)\n",
    "            predict_result = []\n",
    "            clf = self.learner.fit(self.train_X, self.train_Y)\n",
    "            predict_result = clf.predict(self.test_X)\n",
    "            self.abcd = metrices.measures(self.test_Y,predict_result)\n",
    "            self.scores = self._Abcd(self.abcd,F)\n",
    "            self.confusion = metrics.classification_report(self.test_Y.values.tolist(), predict_result, digits=2)\n",
    "            self.params = kwargs\n",
    "        except Exception as e:\n",
    "            a = 10\n",
    "        return self.scores\n",
    "    \n",
    "    def _Abcd(self,abcd , F):\n",
    "        \"\"\"\n",
    "\n",
    "        :param predicted: predicted results(labels)\n",
    "        :param actual: actual results(labels)\n",
    "        :param F: previously got scores\n",
    "        :return: updated scores.\n",
    "        \"\"\"\n",
    "        if 'g-score' in self.goal:\n",
    "            F['g-score'] = [abcd.get_g_score()]\n",
    "            return F\n",
    "        elif 'precision' in self.goal:\n",
    "            F['precision'] = [abcd.get_precision()]\n",
    "            return F\n",
    "        elif 'f1' in self.goal:\n",
    "            F['f1'] = [abcd.calculate_f1_score()]\n",
    "            return F\n",
    "        elif 'd2h' in self.goal:\n",
    "            F['d2h'] = [abcd.calculate_d2h()]\n",
    "            return F\n",
    "\n",
    "    def predict(self,test_X):\n",
    "        return self.learner.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SK_LR(DE_Learners):\n",
    "    def __init__(self, train_x, train_y, predict_x, predict_y, goal):\n",
    "        clf = LogisticRegression()\n",
    "        super(SK_LR, self).__init__(clf, train_x, train_y, predict_x, predict_y,goal)\n",
    "\n",
    "    def get_param(self):\n",
    "        tunelst = {\"penalty\": ['l1', 'l2','elasticnet',None],\n",
    "                   \"multi_class\": ['ovr', 'multinomial','auto'],\n",
    "                   \"C\": [1.0,200.0],\n",
    "                   \"dual\": [True, False],\n",
    "                   \"fit_intercept\": [True, False],\n",
    "                   \"intercept_scaling\": [1.0,100.0],\n",
    "                   \"class_weight\": [\"balanced\", None],\n",
    "                   \"solver\": ['newton-cg','lbfgs','liblinear','sag', 'saga'],\n",
    "                   \"warm_start\": [True, False],\n",
    "                   \"max_iter\": [100,600]}\n",
    "        return tunelst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('/Users/suvodeepmajumder/Documents/AI4SE/git_miner/data/BaseRecyclerViewAdapterHelper_commit.pkl')\n",
    "df1 = df[df['buggy'] == 1]\n",
    "X1 = df1.commit_number\n",
    "X2 = df1.parent\n",
    "X = np.append(X1,X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/suvodeepmajumder/Documents/AI4SE/bellwether_comminity/data/commit_guru/BaseRecyclerViewAdapterHelper.csv'\n",
    "df = prepare_data(path,X)\n",
    "#df,features = get_features(df)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "y = df.fix\n",
    "X = df.drop(labels = ['fix'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20190702_12:53:38 ### Now life is:  20\n",
      "20190702_12:53:38 ### Now life is:  19\n",
      "20190702_12:53:38 ### Now life is:  18\n",
      "20190702_12:53:38 ### Now life is:  17\n",
      "newbestscore {'f1': 0.7777777777777778}:\n",
      "bestconf {'penalty': 'l2', 'multi_class': 'auto', 'C': 19.98, 'dual': True, 'fit_intercept': True, 'intercept_scaling': 88.609, 'class_weight': 'balanced', 'solver': 'liblinear', 'warm_start': False, 'max_iter': 265} :\n",
      "20190702_12:53:38 ### Now life is:  17\n",
      "20190702_12:53:38 ### Now life is:  16\n",
      "20190702_12:53:38 ### Now life is:  15\n",
      "20190702_12:53:38 ### Now life is:  14\n",
      "20190702_12:53:39 ### Now life is:  13\n",
      "20190702_12:53:39 ### Now life is:  12\n",
      "20190702_12:53:39 ### Now life is:  11\n",
      "20190702_12:53:39 ### Now life is:  10\n",
      "20190702_12:53:39 ### Now life is:  9\n",
      "20190702_12:53:39 ### Now life is:  8\n",
      "20190702_12:53:39 ### Now life is:  7\n",
      "newbestscore {'f1': 0.7960222378827031}:\n",
      "bestconf {'penalty': 'l2', 'multi_class': 'auto', 'C': 55.062, 'dual': True, 'fit_intercept': False, 'intercept_scaling': 72.761, 'class_weight': None, 'solver': 'liblinear', 'warm_start': True, 'max_iter': 442} :\n",
      "20190702_12:53:40 ### Now life is:  7\n",
      "20190702_12:53:40 ### Now life is:  6\n",
      "20190702_12:53:40 ### Now life is:  5\n",
      "20190702_12:53:40 ### Now life is:  4\n",
      "20190702_12:53:40 ### Now life is:  3\n",
      "20190702_12:53:40 ### Now life is:  2\n",
      "20190702_12:53:41 ### Now life is:  1\n",
      "20190702_12:53:41 ### Now life is:  0\n",
      "TUNING DONE ! {'penalty': 'l2', 'multi_class': 'auto', 'C': 55.062, 'dual': True, 'fit_intercept': False, 'intercept_scaling': 72.761, 'class_weight': None, 'solver': 'liblinear', 'warm_start': True, 'max_iter': 442} {'f1': 0.7960222378827031}\n",
      "{'f1': [0.0]}\n",
      "'f1'\n"
     ]
    }
   ],
   "source": [
    "commit_list = ['BaseRecyclerViewAdapterHelper']\n",
    "final_score = {}\n",
    "for project in commit_list:\n",
    "    try:\n",
    "        df = pd.read_pickle('/Users/suvodeepmajumder/Documents/AI4SE/git_miner/data/' + project + '_commit.pkl')\n",
    "        df1 = df[df['buggy'] == 1]\n",
    "        X1 = df1.commit_number\n",
    "        X2 = df1.parent\n",
    "        X = np.append(X1,X2)\n",
    "        path = '/Users/suvodeepmajumder/Documents/AI4SE/bellwether_comminity/data/commit_guru/' + project + '.csv'\n",
    "        df = prepare_data(path,X)\n",
    "        df.reset_index(drop=True,inplace=True)\n",
    "        y = df.fix\n",
    "        X = df.drop(labels = ['fix'],axis = 1)\n",
    "        train_X,test_X,train_y,test_y = train_test_split(X, y, test_size=0.33, random_state=13)\n",
    "        df = pd.concat([train_X,train_y], axis = 1)\n",
    "        df.reset_index(drop=True,inplace=True)\n",
    "        y = df.fix\n",
    "        X = df.drop(labels = ['fix'],axis = 1)\n",
    "        kf = StratifiedKFold(n_splits = 5)\n",
    "        goal = 'f1'\n",
    "        learner = [SK_LR][0]\n",
    "        F = {}\n",
    "        score = {}\n",
    "        for i in range(2):\n",
    "            for train_index, tune_index in kf.split(X, y):\n",
    "                X_train, X_tune = X.iloc[train_index], X.iloc[tune_index]\n",
    "                y_train, y_tune = y[train_index], y[tune_index]\n",
    "                _df = pd.concat([X_train,y_train], axis = 1)\n",
    "                _df_tune = pd.concat([X_tune,y_tune], axis = 1)\n",
    "                _df = apply_smote(_df)\n",
    "                _df,selected_cols = apply_cfs(_df)\n",
    "                y_train = _df.fix\n",
    "                X_train = _df.drop(labels = ['fix'],axis = 1)\n",
    "                _df_tune = _df_tune[selected_cols]\n",
    "                y_tune = _df_tune.fix\n",
    "                X_tune = _df_tune.drop(labels = ['fix'],axis = 1)\n",
    "                params, evaluation = tune_learner(learner, X_train, y_train,  X_tune,y_tune, goal)\n",
    "                clf = learner(X_train, y_train,  test_X,test_y, goal)\n",
    "                F = clf.learn(F,**params)\n",
    "                print(F)\n",
    "                score['f1'].append(F['f1'][0])\n",
    "                print(score)\n",
    "                score['precision'].append(F['precision'][0])\n",
    "                print(score)\n",
    "                score['recall'].append(F['recall'][0])\n",
    "                print(score)\n",
    "                score['g-score'].append(F['g-score'][0])\n",
    "                print(score)\n",
    "                score['d2h'].append(F['d2h'][0])\n",
    "                print(score)\n",
    "        project_score.append([project,score])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['BaseRecyclerViewAdapterHelper',\n",
       "  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_score_df = pd.DataFrame(project_score, columns=['project','score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_score_df.to_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canal 0.77\n",
      "zsc 0.86\n",
      "motogp 1.0\n",
      "docker 0.82\n",
      "AndroidSwipeLayout 0.83\n",
      "FizzBuzzEnterpriseEdition 1.0\n",
      "recyclerview-animators 0.8\n",
      "Luban 1.0\n",
      "Fragmentation 0.76\n",
      "tetris_project 1.0\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in range(project_score_df.shape[0]):\n",
    "    if round(np.median(np.array(project_score_df.iloc[i,1])),2) >= .75:\n",
    "        print(project_score_df.iloc[i,0],round(np.median(np.array(project_score_df.iloc[i,1])),2))\n",
    "        cnt+=1\n",
    "print(cnt)\n",
    "    #print(project_score_df.iloc[i,0],round(np.median(np.array(project_score_df.iloc[i,1])),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
