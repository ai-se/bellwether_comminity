{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "import collections\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import platform\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "import timeit\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import SMOTE\n",
    "import feature_selector\n",
    "import DE\n",
    "import CFS\n",
    "import birch\n",
    "import metrics.abcd\n",
    "import birch_bellwether\n",
    "\n",
    "import metrices\n",
    "import measures\n",
    "\n",
    "import sys\n",
    "import traceback\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_driver(df,print_tree = False):\n",
    "    X = df.apply(pd.to_numeric)\n",
    "    cluster = birch.birch(branching_factor=20)\n",
    "        #X.set_index('Project Name',inplace=True)\n",
    "    cluster.fit(X)\n",
    "    cluster_tree,max_depth = cluster.get_cluster_tree()\n",
    "        #cluster_tree = cluster.model_adder(cluster_tree)\n",
    "    if print_tree:\n",
    "        cluster.show_clutser_tree()\n",
    "    return cluster,cluster_tree,max_depth\n",
    "\n",
    "def build_BIRCH(attr_df):\n",
    "    cluster,cluster_tree,_ = cluster_driver(attr_df)\n",
    "    return cluster,cluster_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get cluster wise data for summarzation using median\n",
    "def find_bellwether(data_source1,clusters,path,fold):\n",
    "    df_train = pd.read_pickle(data_source1 + '/train_data.pkl')\n",
    "    cluster,cluster_tree = build_BIRCH(df_train)\n",
    "    cluster_ids = []\n",
    "    cluster_structure = {}\n",
    "    size = {}\n",
    "    for key in cluster_tree:\n",
    "        if cluster_tree[key].depth != None:\n",
    "            cluster_ids.append(key)\n",
    "            if cluster_tree[key].depth not in cluster_structure.keys():\n",
    "                cluster_structure[cluster_tree[key].depth] = {}\n",
    "            cluster_structure[cluster_tree[key].depth][key] = cluster_tree[key].parent_id\n",
    "            size[key] = cluster_tree[key].size\n",
    "    goals = ['recall','precision','pf','pci_20','ifa']\n",
    "    for _ in range(1):\n",
    "        count = 0\n",
    "        count_not = 0\n",
    "        count_yes = 0\n",
    "        score = []\n",
    "        score_med = []\n",
    "        cluster_info = {}\n",
    "        for cluster in clusters:\n",
    "            if cluster.rsplit('/',1)[1] in ['results','cdom_level1']:\n",
    "                continue\n",
    "            df = pd.read_csv(cluster + '/cdom_latest.csv')\n",
    "            counts = {}\n",
    "            med_count = []\n",
    "            c_dom = df.wins.values.tolist()\n",
    "            best_project = df.iloc[c_dom.index(max(c_dom)),0]\n",
    "            for goal in goals:\n",
    "                goal_df = pd.read_csv(cluster + '/1385_LR_bellwether_' + goal + '.csv')\n",
    "                goal_df.rename(columns={'Unnamed: 0':'projects'},inplace=True)\n",
    "                j = goal_df[goal_df['projects'] == best_project].values[0][1:]\n",
    "                if goal == 'pci_20':\n",
    "                    value = sum(i >= 0.40 for i in j)\n",
    "                elif goal != 'pf':\n",
    "                    value = sum(i >= 0.66 for i in j)\n",
    "                else:\n",
    "                    value = sum(i <= 0.33 for i in j)\n",
    "                counts[goal] = value\n",
    "            score_med.append([int(cluster.rsplit('/',1)[1]),\n",
    "                              counts['recall'],\n",
    "                              counts['precision'],\n",
    "                              counts['pf'],\n",
    "                              counts['pci_20'],\n",
    "                              max(c_dom),\n",
    "                              best_project])\n",
    "        score_df = pd.DataFrame(score_med, columns = ['id','count_recall',\n",
    "                                                      'count_precision','count_pf','count_pci_20',\n",
    "                                                      'cdom_score','bellwether'])\n",
    "        score_df = score_df.sort_values('id')\n",
    "        score_df.to_csv(data_source1 + '/bellwether_cdom_2.csv')\n",
    "        level_1_bellwethers = {}\n",
    "        for cluster in cluster_structure[2].keys():\n",
    "            if cluster_structure[2][cluster] not in level_1_bellwethers.keys():\n",
    "                level_1_bellwethers[cluster_structure[2][cluster]] = []\n",
    "            level_1_bellwethers[cluster_structure[2][cluster]].append(score_df[score_df['id'] == cluster].bellwether.values[0])\n",
    "        score_med = []\n",
    "        for key in  level_1_bellwethers.keys():\n",
    "            sub_cluster_bellwethers = level_1_bellwethers[key]\n",
    "            bell = birch_bellwether.bellwether(path,df_train)\n",
    "            final_score = bell.bellwether(sub_cluster_bellwethers,sub_cluster_bellwethers)\n",
    "            with open(data_source1 + '/cdom_level1/cluster_'  + str(key) + '_performance.pkl', 'wb') as handle:\n",
    "                pickle.dump(final_score, handle, protocol=pickle.HIGHEST_PROTOCOL)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "ossim.csv\n",
      "mplayer-ce.csv\n",
      "jfreereport.csv\n",
      "qse.csv\n",
      "turbotrader-bos.csv\n",
      "powerfolder-.csv\n",
      "dvt.csv\n",
      "pixel-commandos.csv\n",
      "modellus.csv\n",
      "google-caja.csv\n",
      "rocrail.csv\n",
      "riff-evolve.csv\n",
      "m-a-d-n-e-s-s.csv\n",
      "ftm.csv\n",
      "kftpgrabber.csv\n",
      "runuomondains.csv\n",
      "amygdala.csv\n",
      "mp-rechnungs-und-kundenverwaltung.csv\n",
      "mclient-mume.csv\n",
      "jatlas.csv\n",
      "retromenu.csv\n",
      "tycho.csv\n",
      "thrust.csv\n",
      "bionote.csv\n",
      "tigermud.csv\n",
      "customsagetv.csv\n",
      "mediaportal.csv\n",
      "gisgraphy.csv\n",
      "tolven.csv\n",
      "panda3d.csv\n",
      "mevenide.csv\n",
      "xreal.csv\n",
      "jvcl.csv\n",
      "mptvseries.csv\n",
      "fm-classic.csv\n",
      "openmeetings.csv\n",
      "reaper-ecad.csv\n",
      "genoviz.csv\n",
      "jcae.csv\n",
      "neodatis-odb.csv\n",
      "opengs.csv\n",
      "taokgame.csv\n",
      "atomsite.csv\n",
      "matrex.csv\n",
      "icescrum.csv\n",
      "stemkit.csv\n",
      "bibedt.csv\n",
      "yarp.csv\n",
      "fluent-nhibernate.csv\n",
      "ossbuild.csv\n",
      "jaxlib.csv\n",
      "1\n",
      "encog-java.csv\n",
      "jfreereport.csv\n",
      "modellus.csv\n",
      "phonon-vlc-mplayer.csv\n",
      "openmeetings.csv\n",
      "httpcontentparser.csv\n",
      "cortex-vfx.csv\n",
      "tzod.csv\n",
      "sigil.csv\n",
      "kmess.csv\n",
      "migen.csv\n",
      "bibedt.csv\n",
      "qcad2.csv\n",
      "qtractor.csv\n",
      "jcae.csv\n",
      "genoviz.csv\n",
      "unimrcp.csv\n",
      "dataobjectsdotnet.csv\n",
      "proftp.csv\n",
      "omseek.csv\n",
      "reaper3d.csv\n",
      "m-m-m.csv\n",
      "scenemonitor.csv\n",
      "servicestack.csv\n",
      "tycho.csv\n",
      "x-ray-mule.csv\n",
      "foursquared.csv\n",
      "raygina.csv\n",
      "m-a-d-n-e-s-s.csv\n",
      "gtad.csv\n",
      "novembre.csv\n",
      "apertium.csv\n",
      "fm-classic.csv\n",
      "jaxlib.csv\n",
      "web-cat.csv\n",
      "jam-daq.csv\n",
      "nassp.csv\n",
      "officefloor.csv\n",
      "continuum-ide.csv\n",
      "gabel.csv\n",
      "tokratan.csv\n",
      "alembik.csv\n",
      "snakeyaml.csv\n",
      "rodin-b-sharp.csv\n",
      "taokgame.csv\n",
      "aztec.csv\n",
      "thrust.csv\n",
      "stuproa-cims.csv\n",
      "rtb-team.csv\n",
      "tolven.csv\n",
      "zxing.csv\n",
      "opennms.csv\n",
      "mptvseries.csv\n",
      "pixel-commandos.csv\n",
      "projecteqemu.csv\n",
      "cities3d.csv\n",
      "quark.csv\n",
      "2\n",
      "logicmail.csv\n",
      "bscwweasel.csv\n",
      "mevenide.csv\n",
      "servicestack.csv\n",
      "papertoolkit.csv\n",
      "freedom-erp.csv\n",
      "poormans.csv\n",
      "avisynth2.csv\n",
      "jam-daq.csv\n",
      "amanda.csv\n",
      "emftriple.csv\n",
      "riff-evolve.csv\n",
      "fm-classic.csv\n",
      "snakeyaml.csv\n",
      "guineu.csv\n",
      "forester-atv.csv\n",
      "kftpgrabber.csv\n",
      "projecteqemu.csv\n",
      "gzigzag.csv\n",
      "exordium.csv\n",
      "mobicents.csv\n",
      "re2c.csv\n",
      "autat.csv\n",
      "reaper-ecad.csv\n",
      "powerfolder-.csv\n",
      "tokratan.csv\n",
      "lportal.csv\n",
      "jguard.csv\n",
      "qmmp.csv\n",
      "maya-work-in-progress.csv\n",
      "kmess.csv\n",
      "metacosm.csv\n",
      "t-2.csv\n",
      "zorannt.csv\n",
      "lufa-lib.csv\n",
      "quark.csv\n",
      "pcsx2.csv\n",
      "sandiaportals.csv\n",
      "uwom.csv\n",
      "genoviz.csv\n",
      "zoolib.csv\n",
      "ondex.csv\n",
      "gtad.csv\n",
      "ktc.csv\n",
      "jstock.csv\n",
      "wxcode.csv\n",
      "customsagetv.csv\n",
      "silvertree.csv\n",
      "libmesh.csv\n",
      "encog-java.csv\n",
      "modellus.csv\n",
      "columba.csv\n",
      "rodin-b-sharp.csv\n",
      "owlib.csv\n",
      "m-a-d-n-e-s-s.csv\n",
      "mptvseries.csv\n",
      "mvdsv.csv\n",
      "rockbox.csv\n",
      "tencompetence.csv\n",
      "jrdf.csv\n",
      "ambulant.csv\n",
      "3\n",
      "mclient-mume.csv\n",
      "jam-daq.csv\n",
      "foursquared.csv\n",
      "matrex.csv\n",
      "dsworkbench.csv\n",
      "freedom-erp.csv\n",
      "forester-atv.csv\n",
      "atunes.csv\n",
      "fluent-nhibernate.csv\n",
      "jaql.csv\n",
      "amanda.csv\n",
      "cortex-vfx.csv\n",
      "kmatplot.csv\n",
      "igarden.csv\n",
      "jajuk.csv\n",
      "wishmaster.csv\n",
      "les-indemodables.csv\n",
      "ondex.csv\n",
      "customsagetv.csv\n",
      "pgui.csv\n",
      "etics.csv\n",
      "officefloor.csv\n",
      "aztec.csv\n",
      "tolven.csv\n",
      "yarp.csv\n",
      "amateur-scrolls.csv\n",
      "sepgsql.csv\n",
      "jcae.csv\n",
      "quark.csv\n",
      "qtwin.csv\n",
      "genoviz.csv\n",
      "omseek.csv\n",
      "xinity.csv\n",
      "xtreemfs.csv\n",
      "lite.csv\n",
      "glas.csv\n",
      "loki-lib.csv\n",
      "wxlua.csv\n",
      "reaper-ecad.csv\n",
      "retromenu.csv\n",
      "agilitybook.csv\n",
      "adaptagrams.csv\n",
      "utgb.csv\n",
      "adobe-source.csv\n",
      "algebsql.csv\n",
      "moving-pictures.csv\n",
      "silvertree.csv\n",
      "theresa.csv\n",
      "proftp.csv\n",
      "emulemorph.csv\n",
      "alembik.csv\n",
      "nassp.csv\n",
      "ctrlr.csv\n",
      "taokgame.csv\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,4):\n",
    "    print(i)\n",
    "    path = '/Users/suvodeepmajumder/Documents/AI4SE/bellwether_comminity/data/1385/converted'\n",
    "    data_source1 = '/Users/suvodeepmajumder/Documents/AI4SE/bellwether_comminity/src/data/1385/exp_new_val/2/fold_' + str(i)\n",
    "    if platform.system() == 'Darwin' or platform.system() == 'Linux':\n",
    "        _dir = data_source1 + '/'\n",
    "    else:\n",
    "        _dir = data_source1 + '\\\\'\n",
    "\n",
    "    clusters = [(join(_dir, f)) for f in listdir(_dir) if Path(join(_dir, f)).is_dir()]\n",
    "    find_bellwether(data_source1,clusters,path,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
