{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "import SMOTE\n",
    "import feature_selector\n",
    "import DE\n",
    "import CFS\n",
    "import metrices\n",
    "import measures\n",
    "\n",
    "import sys\n",
    "import traceback\n",
    "import warnings\n",
    "import os\n",
    "import copy\n",
    "import platform\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from typing import NoReturn\n",
    "from collections import defaultdict\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from threading import Thread\n",
    "from multiprocessing import Queue\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "root = os.path.join(os.getcwd().split('src')[0], 'src')\n",
    "if root not in sys.path:\n",
    "    sys.path.append(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bellwether(object):\n",
    "\n",
    "    def __init__(self,data_source1,data_source2):\n",
    "        self.data_source1 = data_source1\n",
    "        self.data_source2 = data_source2\n",
    "        if platform.system() == 'Darwin' or platform.system() == 'Linux':\n",
    "            _dir1 = self.data_source1 + '/'\n",
    "            _dir2 = self.data_source2 + '/'\n",
    "        else:\n",
    "            _dir1 = self.data_source1 + '\\\\'\n",
    "            _dir2= self.data_source2 + '\\\\'    \n",
    "        self.projects1 = [f for f in listdir(_dir1) if isfile(join(_dir1, f))]\n",
    "        self.projects2 = [f for f in listdir(_dir2) if isfile(join(_dir2, f))]\n",
    "        self.projects1_list = []\n",
    "        for project in self.projects1:\n",
    "            x = project.split('_commit')[0]\n",
    "            if x not in self.projects1_list:\n",
    "                self.projects1_list.append(x)\n",
    "        self.projects1_list = set(self.projects1_list)\n",
    "\n",
    "        self.projects2_list = []\n",
    "        for project in self.projects2:\n",
    "            x = project.split('.csv')[0]\n",
    "            if x not in self.projects2_list:\n",
    "                self.projects2_list.append(x)\n",
    "        self.projects2_list = set(self.projects2_list)\n",
    "\n",
    "        if (self.projects1_list & self.projects2_list): \n",
    "            self.projects = list(self.projects1_list & self.projects2_list)\n",
    "\n",
    "        self.cores = cpu_count()\n",
    "    \n",
    "    def prepare_data(self,path,X):\n",
    "        df = pd.read_csv(path)\n",
    "        #df = df[df['commit_hash'].isin(X)]\n",
    "        df = df.drop(labels = ['commit_hash', 'author_name', 'author_date_unix_timestamp',\n",
    "        'author_email', 'author_date', 'commit_message','classification', 'linked', 'contains_bug', 'fixes',\n",
    "                        'fileschanged','glm_probability', 'rf_probability',\n",
    "        'repository_id', 'issue_id', 'issue_date', 'issue_type'],axis=1)\n",
    "        df = df.dropna()\n",
    "        df = df[['ns', 'nd', 'nf', 'entropy', 'la', 'ld', 'lt', 'ndev', 'age',\n",
    "            'nuc', 'exp', 'rexp', 'sexp','fix']]\n",
    "        df = df.astype(np.float64)\n",
    "        return df\n",
    "\n",
    "    def get_features(self,df):\n",
    "        fs = feature_selector.featureSelector()\n",
    "        df,_feature_nums,features = fs.cfs_bfs(df)\n",
    "        return df,features\n",
    "\n",
    "    def apply_cfs(self,df):\n",
    "        y = df.fix.values\n",
    "        X = df.drop(labels = ['fix'],axis = 1)\n",
    "        X = X.values\n",
    "        selected_cols = CFS.cfs(X,y)\n",
    "        cols = df.columns[[selected_cols]].tolist()\n",
    "        cols.append('fix')\n",
    "        return df[cols],cols\n",
    "        \n",
    "    def apply_smote(self,df):\n",
    "        cols = df.columns\n",
    "        smt = SMOTE.smote(df)\n",
    "        df = smt.run()\n",
    "        df.columns = cols\n",
    "        return df\n",
    "\n",
    "    def tune_learner(self,learner, train_X, train_Y, tune_X, tune_Y, goal,target_class=None):\n",
    "        if not target_class:\n",
    "            target_class = goal\n",
    "        clf = learner(train_X, train_Y, tune_X, tune_Y, goal)\n",
    "        tuner = DE.DE_Tune_ML(clf, clf.get_param(), goal, target_class)\n",
    "        return tuner.Tune()\n",
    "    \n",
    "    def count_per(self,projects):\n",
    "        final_score = {}\n",
    "        for s_project in projects:\n",
    "            print(s_project)\n",
    "            try:\n",
    "                df = pd.read_pickle(self.data_source1 + '/' + s_project + '_commit.pkl')\n",
    "                df1 = df[df['buggy'] == 1]\n",
    "                X1 = df1.commit_number\n",
    "                X2 = df1.parent\n",
    "                X = np.append(X1,X2)\n",
    "                path = self.data_source2 + '/' + s_project + '.csv'\n",
    "                df = self.prepare_data(path,X)\n",
    "                df.reset_index(drop=True,inplace=True)\n",
    "                df_0 = df[df['fix'] == 0]\n",
    "                df_1 = df[df['fix'] == 1]\n",
    "                final_score[s_project] = {'rows': df.shape[0], 'buggy': round(df_1.shape[0]/df.shape[0],2)}\n",
    "            except:\n",
    "                continue\n",
    "        return final_score\n",
    "\n",
    "    def bellwether(self,projects):\n",
    "        final_score = {}\n",
    "        for s_project in projects:\n",
    "            print(s_project)\n",
    "            try:\n",
    "                df = pd.read_pickle(self.data_source1 + '/' + s_project + '_commit.pkl')\n",
    "                df1 = df[df['buggy'] == 1]\n",
    "                X1 = df1.commit_number\n",
    "                X2 = df1.parent\n",
    "                X = np.append(X1,X2)\n",
    "                path = self.data_source2 + '/' + s_project + '.csv'\n",
    "                df = self.prepare_data(path,X)\n",
    "                df.reset_index(drop=True,inplace=True)\n",
    "                y = df.fix\n",
    "                X = df.drop(labels = ['fix'],axis = 1)\n",
    "                train_X,test_X,train_y,test_y = train_test_split(X, y, test_size=0.33, random_state=13)\n",
    "                train_df = pd.concat([train_X,train_y], axis = 1)\n",
    "                test_df = pd.concat([test_X,test_y], axis = 1)\n",
    "                train_df.reset_index(drop=True,inplace=True)\n",
    "                y = train_df.fix\n",
    "                X = train_df.drop(labels = ['fix'],axis = 1)\n",
    "                kf = StratifiedKFold(n_splits = 5)\n",
    "                goal = 'recall'\n",
    "                learner = [SK_LR][0]\n",
    "                F = {}\n",
    "                score = {}\n",
    "                for i in range(1):\n",
    "                    for train_index, tune_index in kf.split(X, y):\n",
    "                        print(i,s_project)\n",
    "                        X_train, X_tune = X.iloc[train_index], X.iloc[tune_index]\n",
    "                        y_train, y_tune = y[train_index], y[tune_index]\n",
    "                        _df = pd.concat([X_train,y_train], axis = 1)\n",
    "                        _df_tune = pd.concat([X_tune,y_tune], axis = 1)\n",
    "                        _df,selected_cols = self.apply_cfs(_df)\n",
    "                        y_train = _df.fix\n",
    "                        X_train = _df.drop(labels = ['fix'],axis = 1)\n",
    "                        _df_tune = _df_tune[selected_cols]\n",
    "                        y_tune = _df_tune.fix\n",
    "                        X_tune = _df_tune.drop(labels = ['fix'],axis = 1)\n",
    "                        _df_test = test_df[selected_cols]\n",
    "                        test_y = _df_test.fix\n",
    "                        test_X = _df_test.drop(labels = ['fix'],axis = 1)\n",
    "                        params, evaluation = self.tune_learner(learner, X_train, y_train,  X_tune,y_tune, goal)\n",
    "                        clf = learner(X_train, y_train,  test_X,test_y, goal)\n",
    "                        F = clf.learn(F,**params)\n",
    "                        _F = copy.deepcopy(F)\n",
    "                        if 'f1' not in score.keys():\n",
    "                            score = _F\n",
    "                        else:\n",
    "                            score['f1'].append(F['f1'][0])\n",
    "                            score['precision'].append(F['precision'][0])\n",
    "                            score['recall'].append(F['recall'][0])\n",
    "                            score['g-score'].append(F['g-score'][0])\n",
    "                            score['d2h'].append(F['d2h'][0])\n",
    "                final_score[s_project] = score\n",
    "            except ValueError:\n",
    "                print(s_project,sys.exc_info())\n",
    "                continue\n",
    "            final_score_df = pd.DataFrame.from_dict(final_score, orient='index')\n",
    "            final_score_df.to_csv('data/commit_guru_self_10_all.csv')\n",
    "        return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DE_Learners(object):\n",
    "    def __init__(self, clf, train_X, train_Y, test_X, test_Y, goal):\n",
    "        \"\"\"\n",
    "\n",
    "        :param clf: classifier, SVM, etc...\n",
    "        :param train_X: training data, independent variables.\n",
    "        :param train_Y: training labels, dependent variables.\n",
    "        :param predict_X: testing data, independent variables.\n",
    "        :param predict_Y: testingd labels, dependent variables.\n",
    "        :param goal: the objective of your tuning, F, recision,....\n",
    "        \"\"\"\n",
    "        self.train_X = train_X\n",
    "        self.train_Y = train_Y\n",
    "        self.test_X = test_X\n",
    "        self.test_Y = test_Y\n",
    "        self.goal = goal\n",
    "        self.param_distribution = self.get_param()\n",
    "        self.learner = clf\n",
    "        self.confusion = None\n",
    "        self.params = None\n",
    "\n",
    "    def apply_smote(self,df,neighbours,r,up_to_num,auto):\n",
    "        cols = df.columns\n",
    "        smt = SMOTE.smote(df,neighbor = neighbours,r = r,up_to_num=up_to_num,auto=auto)\n",
    "        df = smt.run()\n",
    "        df.columns = cols\n",
    "        return df\n",
    "\n",
    "    def learn(self,F, **kwargs):\n",
    "        \"\"\"\n",
    "        :param F: a dict, holds all scores, can be used during debugging\n",
    "        :param kwargs: a dict, all the parameters need to set after tuning.\n",
    "        :return: F, scores.\n",
    "        \"\"\"\n",
    "        self.scores = {self.goal: [0.0]}\n",
    "        try:\n",
    "            neighbours = kwargs.pop('neighbours')\n",
    "            r = kwargs.pop('r')\n",
    "            up_to_num = kwargs.pop('up_to_num')\n",
    "            self.learner.set_params(**kwargs)\n",
    "            _df = pd.concat([self.train_X, self.train_Y], axis = 1)\n",
    "            _df = self.apply_smote(_df,neighbours,r,up_to_num,False)\n",
    "            y_train = _df.fix\n",
    "            X_train = _df.drop(labels = ['fix'],axis = 1)\n",
    "            predict_result = []\n",
    "            clf = self.learner.fit(X_train, y_train)\n",
    "            predict_result = clf.predict(self.test_X)\n",
    "            self.abcd = metrices.measures(self.test_Y,predict_result)\n",
    "            self.scores = self._Abcd(self.abcd,F)\n",
    "            self.confusion = metrics.classification_report(self.test_Y.values.tolist(), predict_result, digits=2)\n",
    "            self.params = kwargs\n",
    "        except Exception as e:\n",
    "            a = 10\n",
    "        return self.scores\n",
    "    \n",
    "    def _Abcd(self,abcd , F):\n",
    "        \"\"\"\n",
    "\n",
    "        :param predicted: predicted results(labels)\n",
    "        :param actual: actual results(labels)\n",
    "        :param F: previously got scores\n",
    "        :return: updated scores.\n",
    "        \"\"\"\n",
    "        if self.goal in ['f1','precision','recall','g-score','d2h']:\n",
    "            F['f1'] = [abcd.calculate_f1_score()]\n",
    "            F['precision'] = [abcd.calculate_precision()]\n",
    "            F['recall'] = [abcd.calculate_recall()]\n",
    "            F['g-score'] = [abcd.get_g_score()]\n",
    "            F['d2h'] = [abcd.calculate_d2h()]\n",
    "            return F\n",
    "        else:\n",
    "            print(\"wronging goal\")\n",
    "            return F\n",
    "\n",
    "    def predict(self,test_X):\n",
    "        return self.learner.predict(test_X)\n",
    "\n",
    "\n",
    "\n",
    "class SK_LR(DE_Learners):\n",
    "    def __init__(self, train_x, train_y, predict_x, predict_y, goal):\n",
    "        clf = LogisticRegression()\n",
    "        super(SK_LR, self).__init__(clf, train_x, train_y, predict_x, predict_y,goal)\n",
    "\n",
    "    def get_param(self):\n",
    "        tunelst = {\"penalty\": ['l1', 'l2','elasticnet','none'],\n",
    "                   \"multi_class\": ['ovr', 'multinomial','auto'],\n",
    "                   \"C\": [1.0,200.0],\n",
    "                   \"dual\": [True, False],\n",
    "                   \"fit_intercept\": [True, False],\n",
    "                   \"intercept_scaling\": [1.0,100.0],\n",
    "                   \"class_weight\": [\"balanced\", 'none'],\n",
    "                   \"solver\": ['newton-cg','lbfgs','liblinear','sag', 'saga'],\n",
    "                   \"warm_start\": [True, False],\n",
    "                   \"max_iter\": [100,600],\n",
    "                   \"neighbours\": [5,21],\n",
    "                   \"r\":[1,6],\n",
    "                   \"up_to_num\": [50,400]}\n",
    "        return tunelst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/suvodeepmajumder/Documents/AI4SE/bellwether_comminity/data'\n",
    "bell = bellwether(path + '/data',path + '/commit_guru')\n",
    "projects = bell.projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bell.bellwether(projects[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bell.count_per(projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
