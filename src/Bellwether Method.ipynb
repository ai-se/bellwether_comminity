{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "import collections\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import platform\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import SMOTE\n",
    "import feature_selector\n",
    "import CFS\n",
    "import birch\n",
    "import metrics.abcd\n",
    "import birch_bellwether\n",
    "\n",
    "import metrices\n",
    "import measures\n",
    "\n",
    "import sys\n",
    "import traceback\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions -\n",
    "## Hierarchical Cluster Creator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Birch Cluster Creator\n",
    "def cluster_driver(df,print_tree = False):\n",
    "    X = df.apply(pd.to_numeric)\n",
    "    cluster = birch.birch(branching_factor=20)\n",
    "        #X.set_index('Project Name',inplace=True)\n",
    "    cluster.fit(X)\n",
    "    cluster_tree,max_depth = cluster.get_cluster_tree()\n",
    "        #cluster_tree = cluster.model_adder(cluster_tree)\n",
    "    if print_tree:\n",
    "        cluster.show_clutser_tree()\n",
    "    return cluster,cluster_tree,max_depth\n",
    "\n",
    "def build_BIRCH(attr_df):\n",
    "    cluster,cluster_tree,_ = cluster_driver(attr_df)\n",
    "    return cluster,cluster_tree\n",
    "\n",
    "def get_clusters(data_source):\n",
    "    if platform.system() == 'Darwin' or platform.system() == 'Linux':\n",
    "        _dir = data_source + '/'\n",
    "    else:\n",
    "        _dir = data_source + '\\\\'\n",
    "\n",
    "    clusters = [(join(_dir, f)) for f in listdir(_dir) if Path(join(_dir, f)).is_dir()]\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions -\n",
    "## Domination Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x,df):\n",
    "    lo = df.min()\n",
    "    hi = df.max()\n",
    "    return (x - lo) / (hi - lo +0.00000001)\n",
    "\n",
    "def dominate(_df,t,row_project_name,goals):\n",
    "    wins = 0\n",
    "    for i in range(_df.shape[0]):\n",
    "        project_name = _df.iloc[i].name\n",
    "        row = _df.iloc[i].tolist()\n",
    "        if project_name != row_project_name:\n",
    "            if dominationCompare(row, t,goals,_df):\n",
    "                wins += 1\n",
    "    return wins\n",
    "\n",
    "def dominationCompare(other_row, t,goals,df):\n",
    "    n = len(goals)\n",
    "    weight = {'recall':1,'precision':1,'pf':-1.5}\n",
    "    sum1, sum2 = 0,0\n",
    "    for i in range(len(goals)):\n",
    "        _df = df[goals[i]]\n",
    "        w = weight[goals[i]]\n",
    "        x = t[i]\n",
    "        y = other_row[i]\n",
    "        x = norm(x,_df)\n",
    "        y = norm(y,_df)\n",
    "        sum1 = sum1 - math.e**(w * (x-y)/n)\n",
    "        sum2 = sum2 - math.e**(w * (y-x)/n)\n",
    "    return sum1/n < sum2/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level 2 Cdom Calculator & Hierarchical Bellwether Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bellwether_level2(data_source,other_projects,path,fold):\n",
    "    goals = ['recall','precision','pf']\n",
    "    clusters = get_clusters(data_source)\n",
    "    for cluster in clusters:\n",
    "        if cluster.rsplit('/',1)[1] == 'results' or cluster.rsplit('/',1)[1] == 'cdom_level1':\n",
    "            continue\n",
    "        projects_performance = {}\n",
    "        for goal in goals:\n",
    "            df = pd.read_csv(cluster + '/1385_LR_bellwether_' + goal + '.csv')\n",
    "            for row in range(df.shape[0]):\n",
    "                j = df.iloc[row].values[1:]\n",
    "                j_med = np.median(j)\n",
    "                project_name = df.iloc[row].values[0]\n",
    "                if project_name not in projects_performance.keys():\n",
    "                    projects_performance[project_name] = {}\n",
    "                projects_performance[project_name][goal] = j_med\n",
    "        _df = pd.DataFrame.from_dict(projects_performance, orient = 'index')\n",
    "        dom_score = []\n",
    "        for row_id in range(_df.shape[0]):\n",
    "            project_name = _df.iloc[row_id].name\n",
    "            row = _df.iloc[row_id].tolist()\n",
    "            wins = dominate(_df,row,project_name,goals)\n",
    "            dom_score.append(wins)\n",
    "        _df['wins'] = dom_score\n",
    "        _df.to_csv(cluster + '/cdom_latest.csv')\n",
    "    return projects_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    print(i)\n",
    "    path = '/Users/suvodeepmajumder/Documents/AI4SE/bellwether_comminity/data/1385/converted'\n",
    "    data_source = '/Users/suvodeepmajumder/Documents/AI4SE/bellwether_comminity/src/data/1385/h_bellwether_exp/level_2/fold_' + str(i)\n",
    "    if platform.system() == 'Darwin' or platform.system() == 'Linux':\n",
    "        _dir = path + '/'\n",
    "    else:\n",
    "        _dir = path + '\\\\'\n",
    "\n",
    "    projects = [f for f in listdir(_dir) if isfile(join(_dir, f))]\n",
    "    find_bellwether_level2(data_source,projects,path,i)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Performance at level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get cluster wise data for summarzation using median\n",
    "def calculate_level_1_performance(data_source,clusters,path,fold):\n",
    "    df_train = pd.read_pickle(data_source + '/train_data.pkl')\n",
    "    cluster,cluster_tree = build_BIRCH(df_train)\n",
    "    cluster_ids = []\n",
    "    cluster_structure = {}\n",
    "    size = {}\n",
    "    for key in cluster_tree:\n",
    "        if cluster_tree[key].depth != None:\n",
    "            cluster_ids.append(key)\n",
    "            if cluster_tree[key].depth not in cluster_structure.keys():\n",
    "                cluster_structure[cluster_tree[key].depth] = {}\n",
    "            cluster_structure[cluster_tree[key].depth][key] = cluster_tree[key].parent_id\n",
    "            size[key] = cluster_tree[key].size\n",
    "    goals = ['recall','precision','pf','pci_20','ifa']\n",
    "    count = 0\n",
    "    score = []\n",
    "    score_med = []\n",
    "    cluster_info = {}\n",
    "    for cluster in clusters:\n",
    "        if cluster.rsplit('/',1)[1] in ['results','cdom_level1']:\n",
    "            continue\n",
    "        df = pd.read_csv(cluster + '/cdom_latest.csv')\n",
    "        counts = {}\n",
    "        med_count = []\n",
    "        c_dom = df.wins.values.tolist()\n",
    "        best_project = df.iloc[c_dom.index(max(c_dom)),0]\n",
    "        for goal in goals:\n",
    "            goal_df = pd.read_csv(cluster + '/1385_LR_bellwether_' + goal + '.csv')\n",
    "            goal_df.rename(columns={'Unnamed: 0':'projects'},inplace=True)\n",
    "            j = goal_df[goal_df['projects'] == best_project].values[0][1:]\n",
    "            if goal == 'pci_20': # check number of projects >= 0.4 when goal is pci_20\n",
    "                value = sum(i >= 0.40 for i in j)\n",
    "            elif goal != 'pf': # check number of projects >= 0.67 when goal is other then pci_20 and pf\n",
    "                value = sum(i >= 0.67 for i in j)\n",
    "            else: # check number of projects <= 0.33 when goal is pf\n",
    "                value = sum(i <= 0.33 for i in j)\n",
    "            counts[goal] = value\n",
    "        score_med.append([int(cluster.rsplit('/',1)[1]),goal_df.shape[0],\n",
    "                          counts['recall'],\n",
    "                          counts['precision'],\n",
    "                          counts['pf'],\n",
    "                          counts['pci_20'],\n",
    "                          max(c_dom),\n",
    "                          best_project])\n",
    "    score_df = pd.DataFrame(score_med, columns = ['id','Total_projects','count_recall',\n",
    "                                                  'count_precision','count_pf','count_pci_20',\n",
    "                                                  'cdom_score','bellwether'])\n",
    "    score_df = score_df.sort_values('id')\n",
    "    score_df.to_csv(data_source + '/bellwether_cdom_2.csv')\n",
    "    level_1_bellwethers = {}\n",
    "    for cluster in cluster_structure[2].keys():\n",
    "        if cluster_structure[2][cluster] not in level_1_bellwethers.keys():\n",
    "            level_1_bellwethers[cluster_structure[2][cluster]] = []\n",
    "        level_1_bellwethers[cluster_structure[2][cluster]].append(score_df[score_df['id'] == cluster].bellwether.values[0])\n",
    "    score_med = []\n",
    "    for key in  level_1_bellwethers.keys():\n",
    "        sub_cluster_bellwethers = level_1_bellwethers[key]\n",
    "        bell = birch_bellwether.bellwether(path,df_train)\n",
    "        final_score = bell.bellwether(sub_cluster_bellwethers,sub_cluster_bellwethers)\n",
    "        with open(data_source + '/cdom_level1/cluster_'  + str(key) + '_performance.pkl', 'wb') as handle:\n",
    "            pickle.dump(final_score, handle, protocol=pickle.HIGHEST_PROTOCOL)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "rcp-company-uibindings.csv\n",
      "mbse.csv\n",
      "jfreereport.csv\n",
      "qse.csv\n",
      "pentahoanalysistool.csv\n",
      "pfaedit.csv\n",
      "dvd-create.csv\n",
      "theresa.csv\n",
      "dest growl-for-windows.csv division by zero\n",
      "ardour.csv\n",
      "google-caja.csv\n",
      "rocrail.csv\n",
      "riff-evolve.csv\n",
      "growl-for-windows.csv\n",
      "dest pfaedit.csv division by zero\n",
      "ftm.csv\n",
      "kftpgrabber.csv\n",
      "runuomondains.csv\n",
      "dest thrust.csv division by zero\n",
      "dest emite.csv division by zero\n",
      "log4net.csv\n",
      "dest mclient-mume.csv division by zero\n",
      "dest tycho.csv division by zero\n",
      "dest thrust.csv division by zero\n",
      "mp-rechnungs-und-kundenverwaltung.csv\n",
      "dest tycho.csv division by zero\n",
      "mclient-mume.csv\n",
      "poormans.csv\n",
      "dest thrust.csv division by zero\n",
      "dest emite.csv division by zero\n",
      "uwom-server.csv\n",
      "tycho.csv\n",
      "thrust.csv\n",
      "bionote.csv\n",
      "dest tycho.csv division by zero\n",
      "emite.csv\n",
      "customsagetv.csv\n",
      "dest tycho.csv division by zero\n",
      "mediaportal.csv\n",
      "dest thrust.csv division by zero\n",
      "lite.csv\n",
      "dest thrust.csv division by zero\n",
      "tolven.csv\n",
      "codesmith.csv\n",
      "mevenide.csv\n",
      "dest poormans.csv division by zero\n",
      "dest tycho.csv division by zero\n",
      "codeblocks.csv\n",
      "stuproa-cims.csv\n",
      "mptvseries.csv\n",
      "dest biodwh.csv division by zero\n",
      "ondex.csv\n",
      "etics.csv\n",
      "autofac.csv\n",
      "genoviz.csv\n",
      "dest bibedt.csv division by zero\n",
      "sigil.csv\n",
      "neodatis-odb.csv\n",
      "unflobtactical.csv\n",
      "monetdb.csv\n",
      "atomsite.csv\n",
      "matrex.csv\n",
      "dest mptvseries.csv division by zero\n",
      "dest etics.csv division by zero\n",
      "dest sigil.csv division by zero\n",
      "dest atomsite.csv division by zero\n",
      "gzigzag.csv\n",
      "stemkit.csv\n",
      "bibedt.csv\n",
      "biodwh.csv\n",
      "dest bibedt.csv division by zero\n",
      "geogebra.csv\n",
      "jstock.csv\n",
      "nodal.csv\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    print(i)\n",
    "    path = '/Users/suvodeepmajumder/Documents/AI4SE/bellwether_comminity/data/1385/converted'\n",
    "    data_source = '/Users/suvodeepmajumder/Documents/AI4SE/bellwether_comminity/src/data/1385/h_bellwether_exp/level_2/fold_' + str(i)\n",
    "    if platform.system() == 'Darwin' or platform.system() == 'Linux':\n",
    "        _dir = data_source + '/'\n",
    "    else:\n",
    "        _dir = data_source + '\\\\'\n",
    "    clusters = [(join(_dir, f)) for f in listdir(_dir) if Path(join(_dir, f)).is_dir()]\n",
    "    calculate_level_1_performance(data_source,clusters,path,i)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level 1 Cdom Calculator & Hierarchical Bellwether Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bellwether_level1(data_source,clusters,path,fold):\n",
    "    df_train = pd.read_pickle(data_source + '/train_data.pkl')\n",
    "    cluster,cluster_tree = build_BIRCH(df_train)\n",
    "    cluster_ids = []\n",
    "    cluster_structure = {}\n",
    "    size = {}\n",
    "    for key in cluster_tree:\n",
    "        if cluster_tree[key].depth != None:\n",
    "            cluster_ids.append(key)\n",
    "            if cluster_tree[key].depth not in cluster_structure.keys():\n",
    "                cluster_structure[cluster_tree[key].depth] = {}\n",
    "            cluster_structure[cluster_tree[key].depth][key] = cluster_tree[key].parent_id\n",
    "            size[key] = cluster_tree[key].size\n",
    "    goals = ['recall','precision','pf']\n",
    "    score_df = pd.read_csv(data_source + '/bellwether_cdom_2.csv')\n",
    "    score_df.drop(labels = ['Unnamed: 0'], axis = 1 ,inplace = True)\n",
    "    level_1_bellwethers = {}\n",
    "    for cluster in cluster_structure[2].keys():\n",
    "        if cluster_structure[2][cluster] not in level_1_bellwethers.keys():\n",
    "            level_1_bellwethers[cluster_structure[2][cluster]] = []\n",
    "        level_1_bellwethers[cluster_structure[2][cluster]].append(score_df[score_df['id'] == cluster].bellwether.values[0])\n",
    "    for cluster in cluster_structure[1].keys():\n",
    "        if cluster not in level_1_bellwethers.keys():\n",
    "            level_1_bellwethers[cluster] = []\n",
    "        level_1_bellwethers[cluster] = list(df_train.iloc[cluster_tree[cluster].data_points].index)\n",
    "    bell_df = {}\n",
    "    for key in  level_1_bellwethers.keys():\n",
    "        sub_cluster_bellwethers = level_1_bellwethers[key]\n",
    "        final_score = pd.read_pickle(data_source + '/cdom_level1/cluster_'  + str(key) + '_performance.pkl')\n",
    "        _results = {}\n",
    "        for goal in goals:    \n",
    "            for s_project in final_score.keys():\n",
    "                if s_project not in _results.keys():\n",
    "                    _results[s_project] = {}\n",
    "                    _temp = []\n",
    "                for d_projects in final_score[s_project].keys():\n",
    "                    if goal == 'g':\n",
    "                        _goal = 'g-score'\n",
    "                    else:\n",
    "                        _goal = goal\n",
    "                    _score = np.median(final_score[s_project][d_projects][_goal])\n",
    "                    _temp.append(np.median(final_score[s_project][d_projects][_goal]))\n",
    "                if goal not in _results[s_project].keys():\n",
    "                    _results[s_project][goal] = []\n",
    "                _results[s_project][goal] = np.median(_temp)\n",
    "        _df = pd.DataFrame.from_dict(_results, orient = 'index')\n",
    "        dom_score = []\n",
    "        for row_id in range(_df.shape[0]):\n",
    "            project_name = _df.iloc[row_id].name\n",
    "            row = _df.iloc[row_id].tolist()\n",
    "            wins = dominate(_df,row,project_name,goals)\n",
    "            dom_score.append(wins)\n",
    "        _df['wins'] = dom_score\n",
    "        c_dom = _df.wins.values.tolist()\n",
    "        best_project = _df.index[c_dom.index(max(c_dom))]\n",
    "        best_project_perf = _df.loc[best_project].values.tolist()\n",
    "        best_project_perf.append(best_project)\n",
    "        bell_df[key] = best_project_perf\n",
    "    perf_df = pd.DataFrame.from_dict(bell_df, orient = 'index', columns = ['recall','precision','pf','cdom','bellwether'])    \n",
    "    perf_df.to_csv(data_source + '/bellwether_cdom_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    path = '/Users/suvodeepmajumder/Documents/AI4SE/bellwether_comminity/data/1385/converted'\n",
    "    data_source = '/Users/suvodeepmajumder/Documents/AI4SE/bellwether_comminity/src/data/1385/h_bellwether_exp/level_2/fold_' + str(i)\n",
    "    if platform.system() == 'Darwin' or platform.system() == 'Linux':\n",
    "        _dir = data_source + '/'\n",
    "    else:\n",
    "        _dir = data_source + '\\\\'\n",
    "    clusters = [(join(_dir, f)) for f in listdir(_dir) if Path(join(_dir, f)).is_dir()]\n",
    "    find_bellwether_level1(data_source,clusters,path,i)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level 0 Cdom Calculator & Hierarchical Bellwether Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get cluster wise data for summarzation using median\n",
    "def find_bellwether_level0(data_source,path,fold):\n",
    "    df_train = pd.read_pickle(data_source + '/train_data.pkl')\n",
    "    cluster,cluster_tree = build_BIRCH(df_train)\n",
    "    cluster_ids = []\n",
    "    cluster_structure = {}\n",
    "    size = {}\n",
    "    for key in cluster_tree:\n",
    "        if cluster_tree[key].depth != None:\n",
    "            cluster_ids.append(key)\n",
    "            if cluster_tree[key].depth not in cluster_structure.keys():\n",
    "                cluster_structure[cluster_tree[key].depth] = {}\n",
    "            cluster_structure[cluster_tree[key].depth][key] = cluster_tree[key].parent_id\n",
    "            size[key] = cluster_tree[key].size\n",
    "    goals = ['recall','precision','pf']\n",
    "    bell_df = {}\n",
    "    score_df = pd.read_csv(data_source + '/bellwether_cdom_1.csv')\n",
    "    score_df = score_df.rename(columns = {'Unnamed: 0':'id'})\n",
    "    _cluster_bellwethers = score_df.bellwether.values.tolist()\n",
    "    bell = birch_bellwether.bellwether(path,score_df)\n",
    "    final_score = bell.bellwether(_cluster_bellwethers,_cluster_bellwethers)\n",
    "    _results = {}\n",
    "    for goal in goals:    \n",
    "        for s_project in final_score.keys():\n",
    "            if s_project not in _results.keys():\n",
    "                _results[s_project] = {}\n",
    "                _temp = []\n",
    "            for d_projects in final_score[s_project].keys():\n",
    "                if goal == 'g':\n",
    "                    _goal = 'g-score'\n",
    "                else:\n",
    "                    _goal = goal\n",
    "                _score = np.median(final_score[s_project][d_projects][_goal])\n",
    "                _temp.append(np.median(final_score[s_project][d_projects][_goal]))\n",
    "            if goal not in _results[s_project].keys():\n",
    "                _results[s_project][goal] = []\n",
    "            _results[s_project][goal] = np.median(_temp)\n",
    "    _df = pd.DataFrame.from_dict(_results, orient = 'index')\n",
    "    dom_score = []\n",
    "    for row_id in range(_df.shape[0]):\n",
    "        project_name = _df.iloc[row_id].name\n",
    "        row = _df.iloc[row_id].tolist()\n",
    "        wins = dominate(_df,row,project_name,goals)\n",
    "        dom_score.append(wins)\n",
    "    _df['wins'] = dom_score\n",
    "    print(_df)\n",
    "    c_dom = _df.wins.values.tolist()\n",
    "    best_project = _df.index[c_dom.index(max(c_dom))]\n",
    "    best_project_perf = _df.loc[best_project].values.tolist()\n",
    "    best_project_perf.append(best_project)\n",
    "    bell_df[key] = best_project_perf\n",
    "    perf_df = pd.DataFrame.from_dict(bell_df, orient = 'index', columns = ['recall','precision','pf','cdom','bellwether'])    \n",
    "    perf_df.to_csv(data_source + '/bellwether_cdom_0.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "qse.csv\n",
      "kftpgrabber.csv\n",
      "tolven.csv\n",
      "jstock.csv\n",
      "benojt.csv\n",
      "emftriple.csv\n",
      "ivef-sdk.csv\n",
      "dest qse.csv division by zero\n",
      "                 recall  precision     pf  wins\n",
      "benojt.csv         1.00      0.500  0.400     5\n",
      "emftriple.csv      0.20      0.460  0.375     1\n",
      "ivef-sdk.csv       0.80      0.445  0.400     2\n",
      "jstock.csv         0.38      0.515  0.370     6\n",
      "kftpgrabber.csv    0.85      0.515  0.430     0\n",
      "qse.csv            0.53      0.710  0.420     3\n",
      "tolven.csv         0.46      0.500  0.380     4\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    print(i)\n",
    "    path = '/Users/suvodeepmajumder/Documents/AI4SE/bellwether_comminity/data/1385/converted'\n",
    "    data_source = '/Users/suvodeepmajumder/Documents/AI4SE/bellwether_comminity/src/data/1385/h_bellwether_exp/level_2/fold_' + str(i)\n",
    "    if platform.system() == 'Darwin' or platform.system() == 'Linux':\n",
    "        _dir = data_source + '/'\n",
    "    else:\n",
    "        _dir = data_source + '\\\\'\n",
    "\n",
    "    clusters = [(join(_dir, f)) for f in listdir(_dir) if Path(join(_dir, f)).is_dir()]\n",
    "    find_bellwether_level0(data_source,path,i)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting foldwise data for default bellwether\n",
    "## **From all comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_bellwether_foldwise_performance(cluster_data_loc,results_loc,fold,data_location):\n",
    "    train_data = pd.read_pickle(cluster_data_loc + '/train_data.pkl')\n",
    "    train_projects = train_data.index.values.tolist()\n",
    "    cluster,cluster_tree,max_depth = cluster_driver(train_data)\n",
    "    test_data = pd.read_pickle(cluster_data_loc + '/test_data.pkl')\n",
    "    test_projects = test_data.index.values.tolist()\n",
    "    goals = ['recall','precision','pf']\n",
    "    for goal in goals:\n",
    "        goal_df = pd.read_csv(results_loc + '/1385_LR_bellwether_' + goal + '.csv')\n",
    "        goal_df.rename(columns = {'Unnamed: 0':'s_project'},inplace = True)\n",
    "        goal_df = goal_df[goal_df['s_project'].isin(train_projects)]\n",
    "        goal_df = goal_df[train_projects]\n",
    "        if not Path(data_location).is_dir():\n",
    "            os.makedirs(Path(data_location))\n",
    "        goal_df.to_csv(data_location + '/bellwether_default_' + goal + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    fold = str(i)\n",
    "    data_location = '/Users/suvodeepmajumder/Documents/AI4SE/bellwether_comminity/src/data/1385/h_bellwether_exp/default_bellwether/fold_' + fold\n",
    "    cluster_data_loc = '/Users/suvodeepmajumder/Documents/AI4SE/bellwether_comminity/src/data/1385/h_bellwether_exp/level_2/fold_' + fold\n",
    "    results_loc = '/Users/suvodeepmajumder/Documents/AI4SE/bellwether_comminity/src/data/1385/h_bellwether_exp/default_bellwether'\n",
    "    get_default_bellwether_foldwise_performance(cluster_data_loc,results_loc,fold,data_location)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level 0 default bellwether Cdom Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_default_bellwether(cluster_data_loc,results_loc,fold,data_location):\n",
    "    train_data = pd.read_pickle(cluster_data_loc + '/train_data.pkl')\n",
    "    train_projects = train_data.index.values.tolist()\n",
    "    test_data = pd.read_pickle(cluster_data_loc + '/test_data.pkl')\n",
    "    test_projects = test_data.index.values.tolist()\n",
    "    goals = ['recall','precision','pf']\n",
    "    projects_performance = {}\n",
    "    train_projects = ['s_project'] + train_projects\n",
    "    for goal in goals:\n",
    "        goal_df = pd.read_csv(results_loc + '/1385_LR_bellwether_' + goal + '.csv')\n",
    "        goal_df.rename(columns = {'Unnamed: 0':'s_project'},inplace = True)\n",
    "        goal_df = goal_df[goal_df['s_project'].isin(train_projects)]\n",
    "        goal_df = goal_df[train_projects]\n",
    "        if not Path(data_location).is_dir():\n",
    "            os.makedirs(Path(data_location))\n",
    "        goal_df.to_csv(data_location + '/bellwether_default_' + goal + '.csv')\n",
    "        for row in range(goal_df.shape[0]):\n",
    "            j = goal_df.iloc[row].values[1:]\n",
    "            j_med = np.median(j)\n",
    "            project_name = goal_df.iloc[row].values[0]\n",
    "            if project_name not in projects_performance.keys():\n",
    "                projects_performance[project_name] = {}\n",
    "            projects_performance[project_name][goal] = j_med\n",
    "    _df = pd.DataFrame.from_dict(projects_performance, orient = 'index')\n",
    "    dom_score = []\n",
    "    for row_id in range(_df.shape[0]):\n",
    "        project_name = _df.iloc[row_id].name\n",
    "        row = _df.iloc[row_id].tolist()\n",
    "        wins = dominate(_df,row,project_name,goals)\n",
    "        dom_score.append(wins)\n",
    "    _df['wins'] = dom_score\n",
    "    _df.to_csv(data_location + '/cdom_latest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    fold = str(i)\n",
    "    data_location = '/Users/suvodeepmajumder/Documents/AI4SE/bellwether_comminity/src/data/1385/h_bellwether_exp/default_bellwether/fold_' + fold\n",
    "    cluster_data_loc = '/Users/suvodeepmajumder/Documents/AI4SE/bellwether_comminity/src/data/1385/h_bellwether_exp/level_2/fold_' + fold\n",
    "    results_loc = '/Users/suvodeepmajumder/Documents/AI4SE/bellwether_comminity/src/data/1385/h_bellwether_exp/default_bellwether'\n",
    "    find_default_bellwether(cluster_data_loc,results_loc,fold,data_location)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level 0 default bellwether Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_default_bellwether_performance(data_source,data_store):\n",
    "    df_train = pd.read_pickle(data_source + '/train_data.pkl')\n",
    "    test_data = pd.read_pickle(data_source + '/test_data.pkl')\n",
    "    test_projects = test_data.index.values.tolist()\n",
    "    cluster_ids = []\n",
    "    cluster_structure = {}\n",
    "    size = {}\n",
    "    goals = ['recall','precision','pf']\n",
    "    for _ in range(1):\n",
    "        count = 0\n",
    "        count_not = 0\n",
    "        count_yes = 0\n",
    "        score = []\n",
    "        score_med = []\n",
    "        cluster_info = {}\n",
    "        for _ in range(1):\n",
    "            df = pd.read_csv(data_store + '/cdom_latest.csv')\n",
    "            counts = {}\n",
    "            med_count = []\n",
    "            c_dom = df.wins.values.tolist()\n",
    "            best_project = df.iloc[c_dom.index(max(c_dom)),0]\n",
    "            for goal in goals:\n",
    "                goal_df = pd.read_csv(data_store + '/bellwether_default_' + goal + '.csv')\n",
    "                goal_df.drop(labels=['Unnamed: 0'],axis = 1, inplace = True)\n",
    "                j = goal_df[goal_df['s_project'] == best_project].values[0][1:]\n",
    "                if goal == 'pci_20':\n",
    "                    value = sum(i >= 0.40 for i in j)\n",
    "                elif goal != 'pf':\n",
    "                    value = sum(i >= 0.66 for i in j)\n",
    "                else:\n",
    "                    value = sum(i <= 0.33 for i in j)\n",
    "                counts[goal] = value\n",
    "            score_med.append([0,\n",
    "                              counts['recall'],\n",
    "                              counts['precision'],\n",
    "                              counts['pf'],\n",
    "                              max(c_dom),\n",
    "                              best_project])\n",
    "        score_df = pd.DataFrame(score_med, columns = ['id','count_recall',\n",
    "                                                      'count_precision','count_pf',\n",
    "                                                      'cdom_score','bellwether'])\n",
    "        score_df = score_df.sort_values('id')\n",
    "        score_df.to_csv(data_store + '/bellwether_cdom_0.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in range(20):\n",
    "    print(fold)\n",
    "    data_source1 = '/Users/suvodeepmajumder/Documents/AI4SE/bellwether_comminity/src/data/1385/h_bellwether_exp/level_2/fold_' + str(fold)\n",
    "    data_store = '/Users/suvodeepmajumder/Documents/AI4SE/bellwether_comminity/src/data/1385/h_bellwether_exp/default_bellwether/fold_' + str(fold)\n",
    "    calculate_default_bellwether_performance(data_source1,data_store)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
