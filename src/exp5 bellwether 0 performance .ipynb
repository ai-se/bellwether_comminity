{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import platform\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import SMOTE\n",
    "import feature_selector\n",
    "import DE\n",
    "import CFS\n",
    "import birch\n",
    "import metrics.abcd\n",
    "import birch_bellwether_v2\n",
    "\n",
    "import metrices\n",
    "import measures\n",
    "\n",
    "import sys\n",
    "import traceback\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get cluster wise data for summarzation using median\n",
    "def find_bellwether(data_source1,data_store,path,fold):\n",
    "    df_train = pd.read_pickle(data_source1 + '/train_data.pkl')\n",
    "    test_data = pd.read_pickle(data_source1 + '/test_data.pkl')\n",
    "    test_projects = test_data.index.values.tolist()\n",
    "    #cluster,cluster_tree = build_BIRCH(df_train)\n",
    "    cluster_ids = []\n",
    "    cluster_structure = {}\n",
    "    size = {}\n",
    "    goals = ['recall','precision','pf','pci_20','ifa']\n",
    "    for _ in range(1):\n",
    "        count = 0\n",
    "        count_not = 0\n",
    "        count_yes = 0\n",
    "        score = []\n",
    "        score_med = []\n",
    "        cluster_info = {}\n",
    "        for _ in range(1):\n",
    "            df = pd.read_csv(data_store + '/cdom_latest.csv')\n",
    "            counts = {}\n",
    "            med_count = []\n",
    "            c_dom = df.wins.values.tolist()\n",
    "            best_project = df.iloc[c_dom.index(max(c_dom)),0]\n",
    "            for goal in goals:\n",
    "                goal_df = pd.read_csv(data_store + '/bellwether_0_' + goal + '.csv')\n",
    "                goal_df.drop(labels=['Unnamed: 0'],axis = 1, inplace = True)\n",
    "                j = goal_df[goal_df['s_project'] == best_project].values[0][1:]\n",
    "                if goal == 'pci_20':\n",
    "                    value = sum(i >= 0.40 for i in j)\n",
    "                elif goal != 'pf':\n",
    "                    value = sum(i >= 0.66 for i in j)\n",
    "                else:\n",
    "                    value = sum(i <= 0.33 for i in j)\n",
    "                counts[goal] = value\n",
    "            score_med.append([0,\n",
    "                              counts['recall'],\n",
    "                              counts['precision'],\n",
    "                              counts['pf'],\n",
    "                              counts['pci_20'],\n",
    "                              max(c_dom),\n",
    "                              best_project])\n",
    "        score_df = pd.DataFrame(score_med, columns = ['id','count_recall',\n",
    "                                                      'count_precision','count_pf','count_pci_20',\n",
    "                                                      'cdom_score','bellwether'])\n",
    "        score_df = score_df.sort_values('id')\n",
    "        score_df.to_csv(data_store + '/bellwether_cdom_0.csv')\n",
    "        #bell = birch_bellwether_v2.bellwether(path,df_train)\n",
    "        #final_score = bell.bellwether([best_project],test_projects)\n",
    "        #with open(data_store + '/cluster_0_performance.pkl', 'wb') as handle:\n",
    "        #    pickle.dump(final_score, handle, protocol=pickle.HIGHEST_PROTOCOL) \n",
    "        #result = {}\n",
    "        #for key in final_score.keys():\n",
    "        #    for key2 in final_score[key].keys():\n",
    "        #        for key3 in final_score[key][key2].keys():\n",
    "        #            if key3 not in result.keys():\n",
    "        #                result[key3] = {}                       \n",
    "        #            result[key3][key2] = np.median(final_score[key][key2][key3])\n",
    "        #for key in result.keys():\n",
    "        #    result_df = pd.DataFrame.from_dict(result[key],orient='index',columns=[key])\n",
    "        #    if not Path(data_store + '/results/').is_dir():\n",
    "        #        os.makedirs(Path(data_store + '/results/'))\n",
    "        #   result_df.to_csv(data_store + '/results/' + key + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "for fold in range(20):\n",
    "    print(fold)\n",
    "    path = '/Users/suvodeepmajumder/Documents/AI4SE/bellwether_comminity/data/1385/converted'\n",
    "    data_source1 = '/Users/suvodeepmajumder/Documents/AI4SE/bellwether_comminity/src/data/1385/exp_new_val/2/fold_' + str(fold)\n",
    "    data_store = '/Users/suvodeepmajumder/Documents/AI4SE/bellwether_comminity/src/data/1385/exp_new_val/0/fold_' + str(fold)\n",
    "    find_bellwether(data_source1,data_store,path,fold)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
